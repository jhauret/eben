{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517644d9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc01250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from external libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import pi\n",
    "import IPython.display as ipd\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import torchaudio\n",
    "\n",
    "# imports from project\n",
    "for module in ['pqmf','temporal_transforms','generator']:\n",
    "    if not os.path.exists(f'./{module}.py'):\n",
    "        !wget \"https://raw.githubusercontent.com/jhauret/eben/main/src/{module}.py\"\n",
    "from pqmf import PseudoQMFBanks\n",
    "from temporal_transforms import TemporalTransforms\n",
    "from generator import GeneratorEBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099d13d8",
   "metadata": {},
   "source": [
    "# Activity 1: PQMF analysis and synthesis of a chirp signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e7ccf",
   "metadata": {},
   "source": [
    "## You can try your own parameters !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b236f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PQMF_BANDS = 6\n",
    "PQMF_KS = 48 # must be divisible by 4 * PQMF_BANDS\n",
    "\n",
    "MAX_FREQ = 8000 #Hz\n",
    "DURATION = 3 # seconds\n",
    "SR=16000 # Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pqmf instance\n",
    "pqmf = PseudoQMFBanks(decimation=PQMF_BANDS, kernel_size=PQMF_KS)\n",
    "\n",
    "# chirp instance\n",
    "chirp = torch.sin(pi*torch.linspace(start=0,end=MAX_FREQ,steps=SR*DURATION)*torch.linspace(0,DURATION,SR*DURATION)) # sin(Ï€ft)\n",
    "chirp = chirp.unsqueeze(0).unsqueeze(0) # torch formalism: (batch_size,channels,time_len)\n",
    "chirp = pqmf.cut_tensor(chirp) # avoid non-matching shapes between original and recomposed signals\n",
    "ipd.Audio(chirp.squeeze(), rate=SR) #play audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc602db",
   "metadata": {},
   "source": [
    "## Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc2bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chirp_decomposed = pqmf(chirp, \"analysis\")\n",
    "chirp_recomposed = torch.sum(pqmf(chirp_decomposed, \"synthesis\"), 1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb6765",
   "metadata": {},
   "source": [
    "## Shapes and Signal Noise Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Original chirp length: {chirp.shape[2]} with {chirp.shape[1]} channel') \n",
    "print(f'Decomposed chirp length: {chirp_decomposed.shape[2]} with {chirp_decomposed.shape[1]} channels')\n",
    "print(f'Recomposed chirp length: {chirp_recomposed.shape[2]} with {chirp.shape[1]} channel')\n",
    "print(f'SNR of chirp_recomposed: {10*torch.log10((chirp_recomposed**2).mean()/((chirp-chirp_recomposed)**2).mean()).item():.2f}dB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4e093",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "time = torch.linspace(0, DURATION, SR*DURATION)\n",
    "\n",
    "# Trace signals\n",
    "fig.add_trace(go.Scatter(x=time, y=chirp.squeeze(),name='Original chirp'))\n",
    "fig.add_trace(go.Scatter(x=time, y=chirp_recomposed.squeeze(),name='Recomposed chirp'))\n",
    "\n",
    "# Trace bands\n",
    "for band in range(PQMF_BANDS):\n",
    "    fig.add_trace(go.Scatter(x=time[::PQMF_BANDS], y=chirp_decomposed[0,band,:]+3*band+3,name=f'band_{1+band}'))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title={'text': (f\"\"\"Temporal representation <br><sup>To align all signals in time domain, bands are dilated by a factor {PQMF_BANDS} </sup>\"\"\"),'y':0.9,'x':0.45,'xanchor': 'center','yanchor': 'top'},\n",
    "    font=dict(family='Latin Modern Roman', size=18),\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    xaxis=dict(title='Time (seconds)',titlefont=dict(family='Latin Modern Roman', size=18)),\n",
    "    yaxis=dict(title='Amplitude',titlefont=dict(family='Latin Modern Roman', size=18)))\n",
    "\n",
    "fig.update_yaxes(tickmode='array',ticktext=['signal']+[f'band_{i+1}' for i in range(PQMF_BANDS)], tickvals=[3*i for i in range(PQMF_BANDS+1)])\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23713ca0",
   "metadata": {},
   "source": [
    "# Activity 2: inference with EBEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37603b7e",
   "metadata": {},
   "source": [
    "## Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe00d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio\n",
    "if not os.path.exists('./nemo.flac'):\n",
    "    !wget \"https://github.com/jhauret/eben/raw/main/docs/audios/nemo.flac\"\n",
    "audio, sr = torchaudio.load('./nemo.flac', normalize=False) # try with your own audio.flac !\n",
    "\n",
    "# load generator weights\n",
    "if not os.path.exists('./generator.ckpt'):\n",
    "    !wget \"https://github.com/jhauret/eben/raw/main/src/generator.ckpt\"\n",
    "weights = torch.load('./generator.ckpt')\n",
    "\n",
    "\n",
    "# Instantiate EBEN's generator\n",
    "generator = GeneratorEBEN(bands_nbr=4, pqmf_ks=32)\n",
    "\n",
    "# Load weights\n",
    "generator.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5942d",
   "metadata": {},
   "source": [
    "## In-ear-like degradation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_audio_corrupted = TemporalTransforms(audio, sr)\n",
    "\n",
    "# degradation\n",
    "tt_audio_corrupted.remove_hf()\n",
    "tt_audio_corrupted.add_noise()\n",
    "\n",
    "# smoothing boarders\n",
    "tt_audio_corrupted.smoothing()\n",
    "\n",
    "# normalize\n",
    "tt_audio_corrupted.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b591c3f5",
   "metadata": {},
   "source": [
    "## Enhance audio with eben model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5aa791",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_corrupted_audio = generator.cut_tensor(tt_audio_corrupted.audio.unsqueeze(0))\n",
    "enhanced_speech, enhanced_speech_decomposed = generator(cut_corrupted_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7636ada",
   "metadata": {},
   "source": [
    "## Listen to results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5c997",
   "metadata": {},
   "source": [
    "### In-ear-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851bbd66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ipd.Audio(tt_audio_corrupted.audio, rate=sr) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfa1c5e",
   "metadata": {},
   "source": [
    "### EBEN enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(enhanced_speech.squeeze().detach(), rate=sr) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb3ce37",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0198932",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio, rate=sr) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
